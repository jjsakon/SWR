{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tempClustScore(list_serialpos, rec_words_serialpos):\n",
    "\n",
    "    from scipy.spatial.distance import euclidean\n",
    "    from scipy.stats import percentileofscore, zscore, pearsonr\n",
    "    #Function to return the percentile ranks of each transition between recalled words in a list,\n",
    "    #given the serial positions of the recalled words of that list\n",
    "   \n",
    "    if len(rec_words_serialpos) > 1:\n",
    "       \n",
    "        rec_words_serialpos = np.array(rec_words_serialpos)\n",
    "        rec_dists = np.array([np.abs(rec_words_serialpos[x+1]-rec_words_serialpos[x]) for x in range(len(rec_words_serialpos)-1)])\n",
    " \n",
    "        #compute percentileRanks\n",
    "        percentileRank = np.zeros(len(rec_words_serialpos)-1); percentileRank[:] = np.nan\n",
    " \n",
    "        #For each recalled word (except the last), get the percentile rank of its transition to the following word\n",
    "        for i in range(len(rec_words_serialpos)-1):\n",
    "            #get list of yet-to-be-seen serial positions\n",
    "            possrec_words_serpos = [x not in rec_words_serialpos[0:i+2] for x in list_serialpos]\n",
    "            possibles = list_serialpos[possrec_words_serpos]\n",
    "           \n",
    "            if len(possibles) > 0:\n",
    "                list_dists_comparison = [np.abs(rec_words_serialpos[i]-possibles[j]) for j in range(len(possibles))]\n",
    "                percentileRank[i] = 1.0-percentileofscore(list_dists_comparison,rec_dists[i],'strict')/100. # should really be 'mean' but ethan did 'strict' but actually it doesn't matter as long as you're not comparing the transition with itself, because there are probably no ties\n",
    "                    #print(percentileRank[i])\n",
    " \n",
    "               \n",
    "    else:\n",
    "        percentileRank = np.nan\n",
    "       \n",
    "    return percentileRank\n",
    " \n",
    " \n",
    "def semClustScore(list_vecs_reduced, rec_words_serialpos, metric='euc'):\n",
    "    #Function to return the percentile ranks of each transition between recalled words in a list,\n",
    "    #given the wordvecs of the list, the indices of that list that were recalled\n",
    "   \n",
    "    if len(rec_words_serialpos) > 1:\n",
    " \n",
    "        list_serialpos = np.arange(1,13)\n",
    "        rec_words_serialpos = np.array(rec_words_serialpos, dtype=int)\n",
    "        rec_vecs_reduced = np.zeros((len(rec_words_serialpos),list_vecs_reduced.shape[1]))\n",
    " \n",
    "        for i, serpos in enumerate(rec_words_serialpos):\n",
    "            if serpos in list_serialpos:\n",
    "                rec_vecs_reduced[i,:] = list_vecs_reduced[serpos-1,:]\n",
    " \n",
    "        if metric=='euc':\n",
    "            rec_dists = np.array([ euclidean(rec_vecs_reduced[x,:],rec_vecs_reduced[x+1,:]) for x in range(len(rec_words_serialpos)-1) ])\n",
    "        elif metric=='cos':\n",
    "            rec_dists = np.array([ cosine(rec_vecs_reduced[x,:],rec_vecs_reduced[x+1,:]) for x in range(len(rec_words_serialpos)-1) ])\n",
    " \n",
    "        percentileRank = np.zeros(len(rec_words_serialpos)-1); percentileRank[:] = np.nan\n",
    "        percentileRank_samecat = np.zeros(len(rec_words_serialpos)-1); percentileRank_samecat[:] = np.nan\n",
    "        percentileRank_diffcat = np.zeros(len(rec_words_serialpos)-1); percentileRank_diffcat[:] = np.nan\n",
    " \n",
    "       #For each recalled word (except the last), get the percentile rank of its transition to the following word\n",
    "        for i in range(len(rec_words_serialpos)-1):\n",
    " \n",
    "            possrec_words_serpos = [x not in rec_words_serialpos[0:i+2] for x in list_serialpos]\n",
    "            possibles = list_vecs_reduced[possrec_words_serpos]\n",
    " \n",
    "            if len(possibles) > 0:   \n",
    "                if metric=='euc':\n",
    "                    list_dists_comparison = [euclidean(rec_vecs_reduced[i,:],possibles[j,:]) for j in range(len(possibles))]\n",
    "                elif metric=='cos':\n",
    "                    list_dists_comparison = [cosine(rec_vecs_reduced[i,:],possibles[j,:]) for j in range(len(possibles))]\n",
    "                percentileRank[i] = 1.0-percentileofscore(list_dists_comparison,rec_dists[i],'strict')/100.\n",
    "               \n",
    "    else:\n",
    "        percentileRank = np.nan\n",
    "   \n",
    "    return percentileRank\n",
    " \n",
    " \n",
    "def getClustRankZscore(percentileRanks, percentileRanks_perm):\n",
    "    #Function to Z-score the semantic or temporal clustering ranks, at the session-level\n",
    "    #percentileRanks should be of shape sessions x list x item [x pcadim]\n",
    "    nsessions = percentileRanks.shape[0]\n",
    " \n",
    "    #For semantic clustering scores\n",
    "    if len(percentileRanks.shape) == 4:\n",
    "        ndim = percentileRanks.shape[3]\n",
    "        nperm = percentileRanks_perm.shape[4]-1\n",
    "        sessClustZscore = np.zeros([nsessions,ndim]); sessClustZscore[:] = np.nan\n",
    "        clustScore_avg = np.zeros([nsessions,ndim]); clustScore_avg[:] = np.nan\n",
    "        clustScore_avg_perm = np.zeros([nsessions,ndim,nperm+1]); clustScore_avg_perm[:] = np.nan\n",
    "       \n",
    "        for s in range(nsessions):\n",
    "            for k in range(ndim):\n",
    "                #first average within lists\n",
    "                listlevelavg = np.nanmean(percentileRanks[s,:,:,k],axis=1) #Order is session x list x item x pcadimension\n",
    "                #then average across lists\n",
    "                clustScore_avg[s,k] = np.nanmean(listlevelavg[:])\n",
    " \n",
    "                for p in range(nperm+1):\n",
    "                    listlevelavg = np.nanmean(percentileRanks_perm[s,:,:,k,p],axis=1)\n",
    "                    clustScore_avg_perm[s,k,p] = np.nanmean(listlevelavg[:])\n",
    " \n",
    "                nullDist = clustScore_avg_perm[s,k,:]\n",
    "                sessClustZscore[s,k] = (clustScore_avg[s,k] - np.nanmean(nullDist))/np.nanstd(nullDist)\n",
    " \n",
    " \n",
    "        clustScore_zscores = np.nanmean(sessClustZscore,axis=0)\n",
    " \n",
    "    #For temporal clustering scores\n",
    "    elif len(percentileRanks.shape) == 3:\n",
    "        nperm = percentileRanks_perm.shape[3]-1\n",
    "        sessClustZscore = np.zeros(nsessions); sessClustZscore[:] = np.nan\n",
    "        clustScore_avg = np.zeros(nsessions); clustScore_avg[:] = np.nan\n",
    "        clustScore_avg_perm = np.zeros([nsessions,nperm+1]); clustScore_avg_perm[:] = np.nan\n",
    " \n",
    "        for s in range(nsessions):\n",
    "            #first average within each list\n",
    "            listlevelavg = np.nanmean(percentileRanks[s,:,:],axis=1)\n",
    "            #then average across lists\n",
    "            clustScore_avg[s] = np.nanmean(listlevelavg)\n",
    "            for p in range(nperm+1):\n",
    "                listlevelavg = np.nanmean(percentileRanks_perm[s,:,:,p],axis=1)\n",
    "                clustScore_avg_perm[s,p] = np.nanmean(listlevelavg[:])\n",
    " \n",
    "            nullDist = clustScore_avg_perm[s,:]\n",
    "            sessClustZscore[s] = (clustScore_avg[s] - np.nanmean(nullDist))/np.nanstd(nullDist)\n",
    " \n",
    "        clustScore_zscores = np.nanmean(sessClustZscore)\n",
    " \n",
    " \n",
    "    return clustScore_zscores\n",
    "\n",
    "def getTransCatAvail(rec_words, rec_words_serialpos, list_words, list_serialpos):\n",
    "    # Returns an array of length(rec_words) with True if only if all four categories of transitions are available from word i to word i+1\n",
    "    rec_words_catnum = np.array(rec_words.category_num)\n",
    "    catEncList = np.array(list_words.category_num)\n",
    "    pairs = [(1,2),(3,4),(5,6),(7,8),(9,10),(11,12)]\n",
    "    pairs_rec = np.zeros(len(pairs))\n",
    " \n",
    "    transCatAvailList = np.ones(len(rec_words)-1,dtype='bool')\n",
    " \n",
    "    for i in range(len(transCatAvailList)):\n",
    "        # first get the serial positions of potential words that can be recalled next\n",
    "        possrec_words_serpos = list_serialpos[[x not in rec_words_serialpos[0:i+1] for x in list_serialpos]]\n",
    " \n",
    "        # then get the categories of the words that can potentially be recalled next\n",
    "        possrec_words_cat = [catEncList[sp-1] for sp in possrec_words_serpos]\n",
    " \n",
    "        # do the same for the current word\n",
    "        curr_word_serpos = rec_words_serialpos[i]\n",
    "        curr_word_cat = rec_words_catnum[i]\n",
    " \n",
    "        # then check if any are adjsame, adjdiff, nonadjsame, or nonadjdiff\n",
    "        adj = np.abs(curr_word_serpos-possrec_words_serpos) == 1\n",
    "        nonadj = np.logical_not(adj)\n",
    "        samecat = curr_word_cat == possrec_words_cat\n",
    "        diffcat = np.logical_not(samecat)\n",
    " \n",
    "        adjsame_num = np.sum(adj & samecat)\n",
    "        adjdiff_num = np.sum(adj & diffcat)\n",
    "        nonadjsame_num = np.sum(nonadj & samecat)\n",
    "        nonadjdiff_num = np.sum(nonadj & diffcat)\n",
    " \n",
    "        #transType_num = np.array([adjsame_num, adjdiff_num, nonadjsame_num, nonadjdiff_num]) # saved as timed2\n",
    "        transType_num = np.array([nonadjsame_num, nonadjdiff_num]) # saved as timed3\n",
    "        #transType_num = np.array([nonadjsame_num, adjsame_num]) # saved as timed4\n",
    " \n",
    "        if np.any(transType_num == 0):\n",
    "            transCatAvailList[i] = False\n",
    "\n",
    "\n",
    "    return transCatAvailList"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "env1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
